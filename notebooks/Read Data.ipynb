{
 "metadata": {
  "name": "",
  "signature": "sha256:54c4707a4ef80ab12e8d3e02ecb7fb0ec777788c71ade44fd9ea5844d9c7dc41"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook reads Yelp data and places information into pandas dataframe pickles and MySQL tables.\n",
      "1. Read data from text (json)\n",
      "2. Save out restaurant info\n",
      "3. Save out mexican restaurant info\n",
      "4. Save data to MySQL"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import json\n",
      "import pymysql as mdb\n",
      "import random\n",
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "1. Read Restaurant data from text (fson)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "a. All restaurant data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Open file and read one json object at a time\n",
      "data = []\n",
      "json_data = open('data/yelp_academic_dataset_business.json')\n",
      "for line in json_data:\n",
      "    data.append(json.loads(line))\n",
      "\n",
      "json_data.close()\n",
      "\n",
      "# Convert to pandas dataframe\n",
      "business_data = pd.DataFrame(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "b. Trim for open businesses in Arizona"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Keep only open businesses\n",
      "business_data = business_data[business_data['open']==True]\n",
      "\n",
      "# Keep only restaurants\n",
      "rest = []\n",
      "for cats in business_data.categories:\n",
      "    category_string = ''.join(cats).lower()\n",
      "    rest.append('restaurant' in category_string)   # keep restaurants\n",
      "                #(('mexican' in category_string) |    # keep mexican and tex-mex\n",
      "                #('tex-mex' in category_string)))\n",
      "\n",
      "restaurant_data = business_data[rest]\n",
      "\n",
      "# Keep restaurants in Pheonix because that's the city with the most mexican restaurants\n",
      "restaurant_data = restaurant_data[restaurant_data['state']=='AZ']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "c. Additional ad-hoc filtering"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Do some more ad-hoc cleaning\n",
      "restaurant_data['city'] = restaurant_data.city.str.lower()\n",
      "to_replace = ['glendale az','pheonix','phoenix sky harbor center','higley']\n",
      "value = ['glendale','phoenix','phoenix','gilbert']\n",
      "restaurant_data['city'].replace(to_replace=to_replace,value=value,inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "2. Read review data from text (json)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "a. All reviews of businesses in the dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Open file and read one json object at a time\n",
      "data = []\n",
      "json_data = open('data/yelp_academic_dataset_review.json')\n",
      "business_ids = restaurant_data['business_id'].values\n",
      "for line in json_data:\n",
      "    tempjson = json.loads(line)\n",
      "    \n",
      "    # Only add to data if the business is a restaurant\n",
      "    if tempjson['business_id'] in business_ids:\n",
      "        data.append(tempjson)\n",
      "\n",
      "json_data.close()\n",
      "\n",
      "# Convert to pandas dataframe\n",
      "review_data = pd.DataFrame(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "3. Write data frames to pickle"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "a. All restaurant and review data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# For fast loading into python\n",
      "restaurant_data.to_pickle('data/restaurant_data.pkl')\n",
      "review_data.to_pickle('data/review_data.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "b. Mexican Restaurants only"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Only keep restaurants and reviews for mexican restaurants\n",
      "mexican_rest = []\n",
      "\n",
      "for restindex in restaurant_data.index:\n",
      "    \n",
      "    # Get Series of categories for this business\n",
      "    categories = restaurant_data.loc[restindex].categories\n",
      "    \n",
      "    # If 'mexican' is in the category list, append True to a list of logicals\n",
      "    if 'mexican' in ''.join(categories).lower():\n",
      "        mexican_rest.append(True)\n",
      "    else:\n",
      "        mexican_rest.append(False)\n",
      "        \n",
      "# Trim restaurant data for only mexican restaurants\n",
      "restaurant_data = restaurant_data[mexican_rest]\n",
      "review_data = review_data[review_data['business_id'].isin(restaurant_data.business_id.values)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# restaurant_data.to_pickle\n",
      "restaurant_data.to_pickle('data/restaurant_data_mexican.pkl')\n",
      "review_data.to_pickle('data/review_data_mexican.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "4. Pandas DataFrame to MySQL"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load dataframes from pickle\n",
      "restaurant_data = pd.read_pickle('data/restaurant_data.pkl')\n",
      "review_data = pd.read_pickle('data/review_data.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Start engine to connect to mysql\n",
      "con = mdb.connect('localhost', 'root', '', 'yelp_sentiment_db', use_unicode=True, charset=\"utf8\") #host, user, password, \n",
      "con.set_charset('utf8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 141
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "a. Restaurant Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up Restaurants data table\n",
      "cur = con.cursor()\n",
      "cur.execute(\"DROP TABLE Restaurants\")\n",
      "cur.execute(\"CREATE TABLE Restaurants (business_id text, business_name text,city text, latitude float, longitude float, business_stars float, review_count int, status text, takeout float, noise float, reservations float, wifi float,parking float, creditcard float, goodforgroup float)\")\n",
      "\n",
      "# Add one row at a time to the Restaurants table\n",
      "for index in restaurant_data.index:\n",
      "    a = restaurant_data.loc[index]\n",
      "    b=str(a.business_id)\n",
      "    d=a['attributes']\n",
      "    a1=0\n",
      "    a2=0\n",
      "    a3=0\n",
      "    a4=0\n",
      "    a5=0\n",
      "    a6=0\n",
      "    a7=0\n",
      "    if 'Take-out' in d.keys():\n",
      "        if d['Take-out']==True:\n",
      "            a1=1\n",
      "        else:\n",
      "            a1=-1\n",
      "    if 'Noise Level' in d.keys():\n",
      "        if d['Noise Level']=='quite':\n",
      "            a2=1\n",
      "        elif d['Noise Level']=='average':\n",
      "            a2=2\n",
      "        elif d['Noise Level']=='loud':\n",
      "            a2=3\n",
      "        else:\n",
      "            a2=4\n",
      "    if 'Takes Reservations' in d.keys():\n",
      "        if d['Takes Reservations']==True:\n",
      "            a3=1\n",
      "        else:\n",
      "            a3=-1\n",
      "    if 'Wi-Fi' in d.keys():\n",
      "        if d['Wi-Fi']==\"free\":\n",
      "            a4=1\n",
      "        else:\n",
      "            a4=-1\n",
      "    if 'Parking' in d.keys():\n",
      "        if True in d['Parking'].values():\n",
      "            a5=1\n",
      "        else:\n",
      "            a5=-1\n",
      "    if 'Accepts Credit Cards' in d.keys():\n",
      "        if d['Accepts Credit Cards']==True:\n",
      "            a6=1\n",
      "        else:\n",
      "            a6=-1\n",
      "    if 'Good For Groups' in d.keys():\n",
      "        if d['Good For Groups']==True:\n",
      "            a7=1\n",
      "        else:\n",
      "            a7=-1\n",
      "            \n",
      "    # Insert values into the dataframe\n",
      "    cmd = u'INSERT INTO Restaurants VALUES (\"{0}\",\"{1}\",\"{2}\",{3},{4},{5},{6},\"{7}\",{8},{9},{10},{11},{12},{13},{14})'.format(a['business_id'].replace('\"', ''),\\\n",
      "a['name'].replace('\"',''),a['city'],a['latitude'],a['longitude'],a['stars'],a['review_count'],a['open'],a1,a2,a3,a4,a5,a6,a7)\n",
      "    cur.execute(cmd)\n",
      "\n",
      "# Commit changes to the database\n",
      "con.commit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 143
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "b. Review Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up Reviews data table\n",
      "cur = con.cursor()\n",
      "#cur.execute(\"DROP TABLE Reviews\")\n",
      "cur.execute(\"CREATE TABLE Reviews (business_id text, review_id text, user_id text, stars float, ymd DATE, content text)\")\n",
      "\n",
      "# Add one row at a time to the Restaurants table\n",
      "for index in review_data.index:\n",
      "    \n",
      "    # Don't know encoding of a some review text\n",
      "    #if index==187856: continue\n",
      "    \n",
      "    a = review_data.loc[index]\n",
      "    \n",
      "    # Insert values into the dataframe\n",
      "    cmd = u'INSERT INTO Reviews VALUES (\"{0}\",\"{1}\",\"{2}\",{3},\"{4}\",\"{5}\")'.format(a['business_id'].replace('\"', ''),\\\n",
      "a['review_id'].replace('\"',''),a['user_id'].replace('\"',''),a['stars'],a['date'],a['text'].replace('\"','').replace('\\n',' ').replace('\\\\','/'))\n",
      "    #if index==63278:\n",
      "    #    pdb.set_trace()\n",
      "    #print index\n",
      "    try:\n",
      "        cur.execute(cmd)\n",
      "    except:\n",
      "        print \"Skipping index value {}\".format(index)\n",
      "        \n",
      "# Commit changes to the database\n",
      "con.commit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Skipping index value 22473\n",
        "Skipping index value 23099"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 42709"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 61001"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 115494"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 144045"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 154061"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 162567"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 173541"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 178415"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 186854"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 187856"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 190152"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 191571"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 204292"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 218730"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 226668"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 231082"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 272157"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Skipping index value 277921"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 145
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "3. Build Sentence DataFrame from reviews"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Divide reviews into individual sentences\n",
      "# Make new table that has: Review_ID+Sentece_ID, sentence \n",
      "sentences = pd.DataFrame(columns=['review_id','sentence_id','text','stars'])\n",
      "total_count = 0\n",
      "for rev_id in trainrev.review_id:\n",
      "    thisreview = trainrev[trainrev.review_id==rev_id]\n",
      "    sents = nltk.sent_tokenize(thisreview.text.values[0])\n",
      "    thissent_count = 0\n",
      "    for sent in sents:\n",
      "        sentid = str(thissent_count).zfill(5)\n",
      "        sentences.loc[total_count] = [thisreview.review_id.values[0],sentid,sent,thisreview.stars.values[0]]\n",
      "        thissent_count += 1\n",
      "        total_count += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "review_data = pd.read_pickle('data/review_data.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}