{
 "metadata": {
  "name": "",
  "signature": "sha256:dd55fd73b3043987a7d5f3f4094d9d8b9cd3d9777a96a66a67f30fb4af4da36a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notbook contains exploration of tokenization and sentiment classification for a single mexican restaurant in phoenix, AZ."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Walkthrough - One Restaurant"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Outline"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Methodology of Blair-Goldensohn et al. 2008: http://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/34368.pdf\n",
      "1. Text extractor (Reviews --> sentences/phrases)\n",
      "2. Sentiment classifier (attach sentiment to each sentence/phrase)\n",
      "3. Aspect Extractor (find target of sentiment in each sentence/phrase)\n",
      "4. Aggregate over each aspect for summary of results"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "0. Load data, import modules"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import nltk\n",
      "import code.potts_tokenizer as ptk\n",
      "from textblob import TextBlob\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Select a single mexican restaurant to test in this sandbox.\n",
      "#restaurant_data = restaurant_data[restaurant_data.mexican]\n",
      "#rest = restaurant_data[restaurant_data.review_count==np.round(restaurant_data.review_count.median())].iloc[0]\n",
      "#rev = review_data[review_data.business_id==rest.business_id]\n",
      "\n",
      "# Save restaurant and review data to pickle for future loading\n",
      "#rest.to_pickle('data/one_restaurant_data.pkl')\n",
      "#rev.to_pickle('data/one_review_data.pkl')\n",
      "\n",
      "# Load data from a single mexican restaurant\n",
      "rest = pd.read_pickle('data/one_restaurant_data.pkl')\n",
      "rev = pd.read_pickle('data/one_review_data.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1. Text Extractor (reviews --> sentences)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Divide reviews into individual sentences\n",
      "# Make new table that has: Review_ID+Sentece_ID, sentence \n",
      "sentences = pd.DataFrame(columns=['review_id','sentence_id','text','stars'])\n",
      "total_count = 0\n",
      "for rev_id in rev.review_id:\n",
      "    thisreview = rev[rev.review_id==rev_id]\n",
      "    sents = nltk.sent_tokenize(thisreview.text.values.astype(str)[0])\n",
      "    thissent_count = 0\n",
      "    for sent in sents:\n",
      "        sentid = str(thissent_count).zfill(5)\n",
      "        sentences.loc[total_count] = [thisreview.review_id.values[0],sentid,sent,thisreview.stars.values[0]]\n",
      "        thissent_count += 1\n",
      "        total_count += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2. Sentiment score (sentences --> sentiment_score)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Explore different ways to calculate sentiment score:\n",
      "   1. Assign the sentiment of the review overall\n",
      "   2. Textblob sentence polarity\n",
      "   3. Build my own sentence polarity measure\n",
      "   Try to get some labeled data. whether from movie reviews (http://www.cs.cornell.edu/people/pabo/movie-review-data/) or other online sentiment polarity datasets.\n",
      "   OR, get Eileen to help me score some sentences manually. OR, bootstrap my own sentiment dictionary starting with some known seed words."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add new columns to sentence dataframe to hold review scores\n",
      "sentences['blob'] = 0\n",
      "sentences['wecht_TBD'] = 0\n",
      "\n",
      "# Calculate sentiment score associated with these sentences\n",
      "Tok = ptk.Tokenizer()   # Potts sentiment tokenizer\n",
      "for ii in range(len(sentences)):\n",
      "    \n",
      "    # Extract tokens from this sentence\n",
      "    #tokens = Tok.tokenize(sentences.iloc[ii].text)\n",
      "    \n",
      "    # -------------- Score sentence in various ways --------------\n",
      "    # 1. using textblob sentence sentiment score\n",
      "    sentences.loc[ii,'blob'] = TextBlob(sentences.iloc[ii].text).sentences[0].sentiment.polarity\n",
      "    \n",
      "    # 2. other ways of scoring sentence sentiment?\n",
      "    # Do some brainstorming and thinking of things. This is a more complex detail to fill in later"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3. Aspect Extractor"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How to find the object of sentiment in each sentence. \n",
      "\n",
      "1. Dynamic Aspect identification (LDA, word frequency, position relative to known sentiment words, etc.). See Blair-Goldensohn 2008 for their process. This will find 1-3 gram strings of text that commonly occur in the reviews. However, this only captures fine-grained information; it doesn't tell you that \"clam chowder\" is part of a broader class called seafood. For that, we need static aspect identification.\n",
      "2. Static Aspect identification. Requires hand-labeled training data. Use a classifer to identify which features of sentences predict the label associated with that sentence."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}